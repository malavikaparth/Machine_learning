{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
        "!unzip -q tiny-imagenet-200.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tDIHPtlcVEv",
        "outputId": "90ac89c3-1921-4546-81a4-f56c3421ef80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-07 11:03:06--  http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
            "Resolving cs231n.stanford.edu (cs231n.stanford.edu)... 171.64.68.10\n",
            "Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248100043 (237M) [application/zip]\n",
            "Saving to: ‘tiny-imagenet-200.zip’\n",
            "\n",
            "tiny-imagenet-200.z 100%[===================>] 236.61M  18.1MB/s    in 23s     \n",
            "\n",
            "2023-01-07 11:03:29 (10.1 MB/s) - ‘tiny-imagenet-200.zip’ saved [248100043/248100043]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjMxbkXa0Kka"
      },
      "outputs": [],
      "source": [
        "#Importing the required libraries\n",
        "import numpy as np\n",
        "from skimage import color\n",
        "import os, time, shutil, argparse\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.color import rgb2lab, rgb2gray, lab2rgb\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "# Check if GPU is available\n",
        "use_gpu = torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#A folder for loading image and converting them to LAB color space\n",
        "class LABImageFolder(datasets.ImageFolder):\n",
        "  '''Custom images folder, which converts images to grayscale before loading'''\n",
        "  def __getitem__(self, index):\n",
        "    path, target = self.imgs[index]\n",
        "    img = self.loader(path)\n",
        "\n",
        "    img_lab = rgb2lab(img)\n",
        "\n",
        "    img_l = img_lab[:,:,0:1]\n",
        "    # shape of img_l is (64,64,1)\n",
        "\n",
        "    img_ab = img_lab[:, :, 1:3]\n",
        "    # shape of img_ab is (64,64,2).\n",
        "\n",
        "    tens_l = torch.from_numpy(img_l.transpose((2, 0, 1))).float()\n",
        "\n",
        "    # The next lines convert the \"ab\" channels to a PyTorch tensor.\n",
        "    tens_ab = torch.from_numpy(img_ab.transpose((2, 0, 1))).float()\n",
        "\n",
        "    return tens_l, tens_ab"
      ],
      "metadata": {
        "id": "jGBl3iHBrDe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_imagefolder = LABImageFolder('/content/tiny-imagenet-200/train')  # gets all images from training folder & turns them into 2 tensors/image!\n",
        "train_loader = torch.utils.data.DataLoader(train_imagefolder, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "TG_QTlpKrDp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_imagefolder = LABImageFolder('/content/tiny-imagenet-200/val')\n",
        "val_loader = torch.utils.data.DataLoader(val_imagefolder, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "PoGAhinqrD7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BaseColor is a custom Class that inherits from Class nn.Module\n",
        "# The CNN model, we use, is a subclass of the BaseColor Class!\n",
        "\n",
        "class BaseColor(nn.Module):\n",
        "\tdef __init__(self):\n",
        "\t\tsuper(BaseColor, self).__init__()\n",
        "\n",
        "\t\tself.l_cent = 50.\n",
        "\t\tself.l_norm = 100.\n",
        "\t\tself.ab_norm = 110.\n",
        "\n",
        "\tdef normalize_l(self, in_l):\n",
        "\t\treturn (in_l-self.l_cent)/self.l_norm\n",
        "\n",
        "\tdef unnormalize_l(self, in_l):\n",
        "\t\treturn in_l*self.l_norm + self.l_cent\n",
        "\n",
        "\tdef normalize_ab(self, in_ab):\n",
        "\t\treturn in_ab/self.ab_norm\n",
        "\n",
        "\tdef unnormalize_ab(self, in_ab):\n",
        "\t\treturn in_ab*self.ab_norm"
      ],
      "metadata": {
        "id": "EIH1X-i9rD9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from IPython import embed\n",
        "\n",
        "class ECCVGenerator(BaseColor):\n",
        "    def __init__(self, norm_layer=nn.BatchNorm2d):   # Why this norm_layer==nn.BatchNorm2d? it is used in several of the models\n",
        "        super(ECCVGenerator, self).__init__()\n",
        "\n",
        "        model1=[nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=True),]  # ok, we go from 1 layer to 64 layers. Where are the filters defined?\n",
        "        model1+=[nn.ReLU(True),]\n",
        "        model1+=[nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=True),]\n",
        "        model1+=[nn.ReLU(True),]\n",
        "        model1+=[norm_layer(64),]\n",
        "\n",
        "        model2=[nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model2+=[nn.ReLU(True),]\n",
        "        model2+=[nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1, bias=True),]\n",
        "        model2+=[nn.ReLU(True),]\n",
        "        model2+=[norm_layer(128),]\n",
        "\n",
        "        model3=[nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model3+=[nn.ReLU(True),]\n",
        "        model3+=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model3+=[nn.ReLU(True),]\n",
        "        model3+=[nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1, bias=True),]\n",
        "        model3+=[nn.ReLU(True),]\n",
        "        model3+=[norm_layer(256),]\n",
        "\n",
        "        model4=[nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model4+=[nn.ReLU(True),]\n",
        "        model4+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model4+=[nn.ReLU(True),]\n",
        "        model4+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model4+=[nn.ReLU(True),]\n",
        "        model4+=[norm_layer(512),]\n",
        "\n",
        "        model5=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n",
        "        model5+=[nn.ReLU(True),]\n",
        "        model5+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n",
        "        model5+=[nn.ReLU(True),]\n",
        "        model5+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n",
        "        model5+=[nn.ReLU(True),]\n",
        "        model5+=[norm_layer(512),]\n",
        "\n",
        "        model6=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n",
        "        model6+=[nn.ReLU(True),]\n",
        "        model6+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n",
        "        model6+=[nn.ReLU(True),]\n",
        "        model6+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n",
        "        model6+=[nn.ReLU(True),]\n",
        "        model6+=[norm_layer(512),]\n",
        "\n",
        "        model7=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model7+=[nn.ReLU(True),]\n",
        "        model7+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model7+=[nn.ReLU(True),]\n",
        "        model7+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model7+=[nn.ReLU(True),]\n",
        "        model7+=[norm_layer(512),]\n",
        "\n",
        "        model8=[nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=True),]\n",
        "        model8+=[nn.ReLU(True),]\n",
        "        model8+=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model8+=[nn.ReLU(True),]\n",
        "        model8+=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model8+=[nn.ReLU(True),] # <- original, normally followed by a 256 -> 313 ... and then softmax!\n",
        "        # The relu is outputting values from 0 to infinity!\n",
        "\n",
        "\n",
        "        # model8+=[nn.Conv2d(256, 313, kernel_size=1, stride=1, padding=0, bias=True),] # <- changed by Dirk, actually not doing this thing at all\n",
        "        # model8+=[nn.Conv2d(256, 313, kernel_size=1, stride=1, padding=0, bias=True),]  <- original\n",
        "        # What would be the range of values after this conv2d? Before moving to softmax?\n",
        "        # kernel_size = 1 --> no filter of feature extractor!!!\n",
        "        # stride = 1 --> horizontal + vertical size remains the same!!\n",
        "        # This layer was only to go to 313 layers, without changing spatial dimensions!\n",
        "        # We don\n",
        "\n",
        "        self.model1 = nn.Sequential(*model1)\n",
        "        self.model2 = nn.Sequential(*model2)\n",
        "        self.model3 = nn.Sequential(*model3)\n",
        "        self.model4 = nn.Sequential(*model4)\n",
        "        self.model5 = nn.Sequential(*model5)\n",
        "        self.model6 = nn.Sequential(*model6)\n",
        "        self.model7 = nn.Sequential(*model7)\n",
        "        self.model8 = nn.Sequential(*model8)\n",
        "\n",
        "        # self.softmax = nn.Softmax(dim=1)  # what does it mean to softmax over dimension 1? Dimension 1 is the number of layers in the tensor!\n",
        "        # self.model_out = nn.Conv2d(313, 2, kernel_size=1, padding=0, dilation=1, stride=1, bias=False)  <- original code\n",
        "        self.model_out = nn.Conv2d(256, 2, kernel_size=1, padding=0, dilation=1, stride=1, bias=False) # <- changed by Dirk\n",
        "        self.upsample4 = nn.Upsample(scale_factor=4, mode='bilinear')\n",
        "\n",
        "    def forward(self, input_l):\n",
        "        conv1_2 = self.model1(self.normalize_l(input_l))   # normalizing \"l\" <- one of the functions/methods in base_color.py\n",
        "        # Attention we are normalizing the values here, so there is a problem if they already have been normalised!!!\n",
        "        conv2_2 = self.model2(conv1_2)\n",
        "        conv3_3 = self.model3(conv2_2)\n",
        "        conv4_3 = self.model4(conv3_3)\n",
        "        # conv5_3 = self.model5(conv4_3)\n",
        "        # conv6_3 = self.model6(conv5_3)\n",
        "        conv7_3 = self.model7(conv4_3)   #conv6_3\n",
        "        conv8_3 = self.model8(conv7_3)\n",
        "        # out_reg = self.model_out(self.softmax(conv8_3)) <- original\n",
        "        out_reg = self.model_out(conv8_3) # <- changed by Dirk not using the softmax!!!!\n",
        "\n",
        "        return self.unnormalize_ab(self.upsample4(out_reg))      # unnormalizing \"ab\" <- one of the functions/methods in base_color.py\n",
        "        # to unnormalize_ab() it is required the values before unnormalizing are between -1 and 1 <-- tanh needed or not?\n",
        "        # How was assured that values would be -1 to 1 before? Ah, there was a softmax, but followed by model_out (i.e. conv2d)!!!\n",
        "        # Let's not go from 256 to 313, let's not softmax, let's not do a special model\n",
        "\n",
        "def eccv16(pretrained=True):\n",
        "\t   model = ECCVGenerator()\n",
        "\t   if(pretrained):\n",
        "\t\t     import torch.utils.model_zoo as model_zoo\n",
        "\t\t     model.load_state_dict(model_zoo.load_url('https://colorizers.s3.us-east-2.amazonaws.com/colorization_release_v2-9b330a0b.pth',map_location='cpu',check_hash=True))\n",
        "\t   return model"
      ],
      "metadata": {
        "id": "3OqbDdGWrEAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=eccv16(pretrained=False)\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "# print(model)"
      ],
      "metadata": {
        "id": "chQEEIPLrECX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "criterion = nn.L1Loss()"
      ],
      "metadata": {
        "id": "zEvvUF90rEF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)"
      ],
      "metadata": {
        "id": "D8IwZEQ92hP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, model, criterion, optimizer, epochs = 3):\n",
        "  for i in range(epochs):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    print(\"Epoch:\", i+1)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for i_batch, (input_l_batch, input_ab_batch) in enumerate(train_loader):             # i_batch is the batch number\n",
        "\n",
        "      if use_gpu: input_l_batch, input_ab_batch = input_l_batch.cuda(), input_ab_batch.cuda() # Load them in GPU, if available\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      output_ab = model(input_l_batch)\n",
        "\n",
        "      # Determine loss function\n",
        "      loss = criterion(output_ab, input_ab_batch)\n",
        "\n",
        "      # Back propagation\n",
        "      loss.backward()\n",
        "\n",
        "      # Updates weights\n",
        "      optimizer.step()\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "    # Print loss Every Epoch\n",
        "    print(\"Train Loss: \", epoch_loss / len(train_imagefolder))\n",
        "  # https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-model-for-inference\n",
        "  torch.save(model,'pretrained_regression_model.pth')"
      ],
      "metadata": {
        "id": "tPSpFqmZ2jy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(train_loader=train_loader, model=model, criterion=criterion, optimizer=optimizer, epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "z7y6ucWc2mZk",
        "outputId": "352b7bdb-17ec-4825-b3f8-4e741202b608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-87ada7c34147>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-e6cdeadce530>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epochs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0;31m# Back propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0;31m# Updates weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(val_loader, model, criterion, optimizer, epochs = 3):\n",
        "  for i in range(epochs):\n",
        "\n",
        "    val_total_loss = 0\n",
        "    print(\"Epoch:\", i+1)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for i_batch, (input_l_batch, input_ab_batch) in enumerate(val_loader):# i_batch is the batch number\n",
        "\n",
        "      if use_gpu: input_l_batch, input_ab_batch = input_l_batch.cuda(), input_ab_batch.cuda() # Load them in GPU, if available\n",
        "\n",
        "      with torch.no_grad():\n",
        "        output_ab = model(input_l_batch)\n",
        "        # Determine loss function\n",
        "        loss = criterion(output_ab, input_ab_batch)\n",
        "\n",
        "      val_total_loss += loss.item()\n",
        "\n",
        "    # Print loss Every Epoch\n",
        "    print(\"Validation Loss: \", val_total_loss / len(val_imagefolder))"
      ],
      "metadata": {
        "id": "wO6er2gK2oaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validate(val_loader=val_loader, model=model, criterion=criterion, optimizer=optimizer, epochs=2)"
      ],
      "metadata": {
        "id": "UoF_mXvi2qbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_regression_model = torch.load('pretrained_regression_model.pth')\n",
        "if torch.cuda.is_available():\n",
        "     pretrained_regression_model.cuda()"
      ],
      "metadata": {
        "id": "WDYzaMrM2sXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def postprocess_tens(tens_l, out_ab):\n",
        "\tout_lab = torch.cat((tens_l, out_ab), dim=1)\n",
        "\treturn color.lab2rgb(out_lab.data.cpu().numpy()[0,...].transpose((1,2,0)))"
      ],
      "metadata": {
        "id": "L_VdQ9Tq2uU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range (10000,10200):\n",
        "  tens_l, tens_ab = train_imagefolder[i]\n",
        "  if use_gpu:\n",
        "    tens_l, tens_ab = tens_l.cuda(), tens_ab.cuda()\n",
        "  tens_l = tens_l.unsqueeze(0) # needed because model takes into account batch dimension\n",
        "  tens_ab = tens_ab.unsqueeze(0) # needed because model takes into account batch dimension\n",
        "  tens_ab_out = model(tens_l)\n",
        "  print(tens_ab_out.size())\n",
        "  print(tens_ab.size())\n",
        "  image = postprocess_tens(tens_l, tens_ab_out)\n",
        "  plt.imshow(image)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "oN617AAz2w7-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}